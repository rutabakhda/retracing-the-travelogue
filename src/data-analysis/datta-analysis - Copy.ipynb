{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chapterNo</th>\n",
       "      <th>chapterTitle</th>\n",
       "      <th>sectionNo</th>\n",
       "      <th>sectionTitle</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PART 1</td>\n",
       "      <td>1</td>\n",
       "      <td>Power and Magnificence of Kublai</td>\n",
       "      <td>Now I am to give you a wonderful account of th...</td>\n",
       "      <td>give wonderful account greatest king tartars s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PART 1</td>\n",
       "      <td>1</td>\n",
       "      <td>Power and Magnificence of Kublai</td>\n",
       "      <td>That name is assuredly well merited, since he ...</td>\n",
       "      <td>name assuredly well merited since powerful peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>PART 1</td>\n",
       "      <td>1</td>\n",
       "      <td>Power and Magnificence of Kublai</td>\n",
       "      <td>Whosoever descends in the direct line from Gen...</td>\n",
       "      <td>whosoever descends direct line gengis entitled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>PART 1</td>\n",
       "      <td>1</td>\n",
       "      <td>Power and Magnificence of Kublai</td>\n",
       "      <td>He began to reign in the year of our Lord 1256...</td>\n",
       "      <td>began reign year lord 1256and maintained domin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PART 1</td>\n",
       "      <td>1</td>\n",
       "      <td>Power and Magnificence of Kublai</td>\n",
       "      <td>His brothers sought to oppose his succession, ...</td>\n",
       "      <td>brothers sought oppose succession bravery righ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>PART 1</td>\n",
       "      <td>1</td>\n",
       "      <td>Power and Magnificence of Kublai</td>\n",
       "      <td>t From the beginning of his reign, forty-two y...</td>\n",
       "      <td>beginning reign fortytwo years elapsed present...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>PART 1</td>\n",
       "      <td>1</td>\n",
       "      <td>Power and Magnificence of Kublai</td>\n",
       "      <td>He is now full eighty-five years old, and befo...</td>\n",
       "      <td>full eightyfive years old accession commanded ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>PART 1</td>\n",
       "      <td>1</td>\n",
       "      <td>Power and Magnificence of Kublai</td>\n",
       "      <td>But since that time he has joined the army onl...</td>\n",
       "      <td>since time joined army year 1286 tell occasion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>PART 1</td>\n",
       "      <td>10</td>\n",
       "      <td>His magnificent Palace in Kambalu</td>\n",
       "      <td>He resides in the vast city of Kambalu, three ...</td>\n",
       "      <td>resides vast city kambalu three months year de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>PART 1</td>\n",
       "      <td>10</td>\n",
       "      <td>His magnificent Palace in Kambalu</td>\n",
       "      <td>It is a complete square, a mile long on every ...</td>\n",
       "      <td>complete square mile long every side whole fou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chapterNo chapterTitle  sectionNo                       sectionTitle  \\\n",
       "0          1       PART 1          1   Power and Magnificence of Kublai   \n",
       "1          1       PART 1          1   Power and Magnificence of Kublai   \n",
       "2          1       PART 1          1   Power and Magnificence of Kublai   \n",
       "3          1       PART 1          1   Power and Magnificence of Kublai   \n",
       "4          1       PART 1          1   Power and Magnificence of Kublai   \n",
       "5          1       PART 1          1   Power and Magnificence of Kublai   \n",
       "6          1       PART 1          1   Power and Magnificence of Kublai   \n",
       "7          1       PART 1          1   Power and Magnificence of Kublai   \n",
       "8          1       PART 1         10  His magnificent Palace in Kambalu   \n",
       "9          1       PART 1         10  His magnificent Palace in Kambalu   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  Now I am to give you a wonderful account of th...   \n",
       "1  That name is assuredly well merited, since he ...   \n",
       "2  Whosoever descends in the direct line from Gen...   \n",
       "3  He began to reign in the year of our Lord 1256...   \n",
       "4  His brothers sought to oppose his succession, ...   \n",
       "5  t From the beginning of his reign, forty-two y...   \n",
       "6  He is now full eighty-five years old, and befo...   \n",
       "7  But since that time he has joined the army onl...   \n",
       "8  He resides in the vast city of Kambalu, three ...   \n",
       "9  It is a complete square, a mile long on every ...   \n",
       "\n",
       "                                    sentence_cleaned  \n",
       "0  give wonderful account greatest king tartars s...  \n",
       "1  name assuredly well merited since powerful peo...  \n",
       "2  whosoever descends direct line gengis entitled...  \n",
       "3  began reign year lord 1256and maintained domin...  \n",
       "4  brothers sought oppose succession bravery righ...  \n",
       "5  beginning reign fortytwo years elapsed present...  \n",
       "6  full eightyfive years old accession commanded ...  \n",
       "7     since time joined army year 1286 tell occasion  \n",
       "8  resides vast city kambalu three months year de...  \n",
       "9  complete square mile long every side whole fou...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "basepath = os.path.dirname(os.path.abspath('__file__'))\n",
    "datapath = basepath + '/data/hugh-murray/'\n",
    "readfile1 = 'chapter1/chapter1-processed.csv'\n",
    "readfile2 = 'chapter2/chapter2-processed.csv'\n",
    "readfile3 = 'chapter3/chapter3-processed.csv'\n",
    "readfile_total = 'chapters-combined-processed.csv'\n",
    "\n",
    "df1 = pd.read_csv(datapath + readfile1,sep='\\t',encoding='ISO-8859-1')\n",
    "df2 = pd.read_csv(datapath + readfile2,sep='\\t',encoding='ISO-8859-1')\n",
    "df3 = pd.read_csv(datapath + readfile3,sep='\\t',encoding='ISO-8859-1')\n",
    "df_total = pd.read_csv(datapath + readfile_total,sep=',',encoding='ISO-8859-1')\n",
    "\n",
    "def handle_empty_values(df):\n",
    "    df.dropna(axis=0, how='any', thresh=None, subset=None, inplace=True)\n",
    "    df.reset_index()\n",
    "    return df\n",
    "    \n",
    "df1 = handle_empty_values(df1)\n",
    "df2 = handle_empty_values(df2)\n",
    "df3 = handle_empty_values(df3)\n",
    "df_total = handle_empty_values(df_total)\n",
    "df_total.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sections(df):\n",
    "    return df.groupby([\"sectionNo\",\"chapterNo\"]).size().count()\n",
    "\n",
    "def get_records(df):\n",
    "    return df.shape[0]\n",
    "\n",
    "def average_sentence_per_section(df):\n",
    "    return df.groupby([\"sectionNo\",\"chapterNo\"]).size().mean()\n",
    "\n",
    "\n",
    "list_sections = [get_sections(df1),get_sections(df2), get_sections(df3), get_sections(df_total)]\n",
    "list_records = [get_records(df1), get_records(df2), get_records(df3), get_records(df_total)]\n",
    "list_sentence_average = [average_sentence_per_section(df1), average_sentence_per_section(df2), average_sentence_per_section(df3), average_sentence_per_section(df_total)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0f5bca41c2fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mchapter1_common_words_one_gram\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchapter1_total_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchapter1_unique_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_top_n_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mchapter2_common_words_one_gram\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchapter2_total_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchapter2_unique_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_top_n_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mchapter3_common_words_one_gram\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchapter3_total_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchapter3_unique_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_top_n_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_top_n_words(corpus, n=None,n_gram=None):\n",
    "    vec = CountVectorizer(ngram_range=(n_gram,n_gram)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    \n",
    "    total_words =sum(freq for word,freq in words_freq)\n",
    "    total_unique_words = len(words_freq) \n",
    "    \n",
    "    return words_freq[:n],total_words,total_unique_words\n",
    "\n",
    "    \n",
    "chapter1_common_words_one_gram,chapter1_total_words,chapter1_unique_words = get_top_n_words(df1['sentence'], 20,1)\n",
    "chapter2_common_words_one_gram,chapter2_total_words,chapter2_unique_words = get_top_n_words(df2['sentence'], 20,1)\n",
    "chapter3_common_words_one_gram,chapter3_total_words,chapter3_unique_words = get_top_n_words(df3['sentence'], 20,1)\n",
    "combine_common_words_one_gram,combine_total_words,combine_unique_words = get_top_n_words(df_total['sentence'], 20,1)\n",
    "\n",
    "#show_plot(common_words_tri_gram)\n",
    "\n",
    "list_total_words = [chapter1_total_words ,chapter2_total_words ,chapter3_total_words,combine_total_words ]\n",
    "list_total_unique_words = [chapter1_unique_words ,chapter2_unique_words ,chapter3_unique_words,combine_unique_words ]\n",
    "\n",
    "list_of_tuples = list(zip(list_sections,list_records,list_sentence_average,list_total_words,list_total_unique_words))  \n",
    "    \n",
    "# Converting lists of tuples into pandas Dataframe.  \n",
    "df_statistics = pd.DataFrame(list_of_tuples, columns = ['Total Sections', 'Total Sentences','Avg no of sentences','Total words','Total unique words'])  \n",
    "\n",
    "new_index = pd.Series(['Chapter1', 'Chapter2', 'Chapter3','Total'])\n",
    "\n",
    "df_statistics.set_index(new_index, inplace = True) \n",
    "\n",
    "df_statistics.head().style.set_properties(**{'background-color': 'white',                                                   \n",
    "                                    'color': 'black',                       \n",
    "                                    'border-color': 'black'})\n",
    "\n",
    "#for word, freq in common_words:\n",
    "#    print(word, freq)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_total' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-27f2f1c262f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_combine_common_words_one_gram\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclean_chapter1_total_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclean_chapter1_unique_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_top_n_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_total\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence_cleaned'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#clean_chapter2_common_words_one_gram,clean_chapter2_total_words,clean_chapter2_unique_words = get_top_n_words(df2['sentence_cleaned'], 20,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#clean_chapter3_common_words_one_gram,clean_chapter3_total_words,clean_chapter3_unique_words = get_top_n_words(df3['sentence_cleaned'], 20,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcombine_common_words_bi_gram\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchapter1_total_bi_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchapter1_bi_unique_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_top_n_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_total\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_total' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "clean_combine_common_words_one_gram,clean_chapter1_total_words,clean_chapter1_unique_words = get_top_n_words(df_total['sentence_cleaned'], 20,1)\n",
    "#clean_chapter2_common_words_one_gram,clean_chapter2_total_words,clean_chapter2_unique_words = get_top_n_words(df2['sentence_cleaned'], 20,1)\n",
    "#clean_chapter3_common_words_one_gram,clean_chapter3_total_words,clean_chapter3_unique_words = get_top_n_words(df3['sentence_cleaned'], 20,1)\n",
    "\n",
    "combine_common_words_bi_gram,chapter1_total_bi_words,chapter1_bi_unique_words = get_top_n_words(df_total['sentence'], 20,2)\n",
    "combine_common_words_tri_gram,chapter1_total_tri_words,chapter1_tri_unique_words = get_top_n_words(df_total['sentence'], 20,3)\n",
    "\n",
    "clean_combine_common_words_bi_gram,clean_chapter1_total_bi_words,clean_chapter1_bi_unique_words = get_top_n_words(df_total['sentence_cleaned'], 20,2)\n",
    "clean_combine_common_words_tri_gram,clean_chapter1_total_tri_words,clean_chapter1_tri_unique_words = get_top_n_words(df_total['sentence_cleaned'], 20,3)\n",
    "\n",
    "def show_plot(common_words,clean_common_words):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    df1 = pd.DataFrame(common_words, columns = ['Original Text' , 'count'])\n",
    "    df1.groupby('Original Text').sum()['count'].sort_values(ascending=False).plot.bar()\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    df1 = pd.DataFrame(clean_common_words, columns = ['Cleaned Text' , 'count'])\n",
    "    df1.groupby('Cleaned Text').sum()['count'].sort_values(ascending=False).plot.bar()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_plot(combine_common_words_one_gram,clean_combine_common_words_one_gram)\n",
    "show_plot(combine_common_words_bi_gram,clean_combine_common_words_bi_gram)\n",
    "show_plot(combine_common_words_tri_gram,clean_combine_common_words_tri_gram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2b50bfc6e309>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mblob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpos_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpos_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "blob = TextBlob(str(df1['sentence']))\n",
    "pos_df = pd.DataFrame(blob.tags, columns = ['word' , 'pos'])\n",
    "pos_df = pos_df.pos.value_counts()[:20]\n",
    "pos_df.plot.bar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['review_len'] = df['sentence'].astype(str).apply(len)\n",
    "#df['word_count'] = df['sentence'].apply(lambda x: len(str(x).split()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
